{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqNGOivdRwWb",
        "outputId": "bf07f800-6084-40bc-c99b-bb2a83494fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/9.6 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m6.8/9.6 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium --quiet\n",
        "!apt-get update > /dev/null\n",
        "!apt install chromium-chromedriver --yes > /dev/null\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0, '/usr/lib/chromium-browser/chromedriver')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from selenium.webdriver import Chrome\n",
        "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from urllib.parse import urljoin\n",
        "from tqdm import tqdm\n",
        "import time"
      ],
      "metadata": {
        "id": "BXHyal_LR1ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HOMEPAGE = \"http://books.toscrape.com\""
      ],
      "metadata": {
        "id": "b3LFCvBOS4JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAllBookUrls(driver, startUrl):\n",
        "    \"\"\"\n",
        "    Phase 1: Navigates through the entire catalog to collect the URLs of each book.\n",
        "    \"\"\"\n",
        "    print(\"Phase 1: Collecting all book URLs...\")\n",
        "    driver.get(startUrl)\n",
        "    bookUrls = []\n",
        "\n",
        "    while True:\n",
        "        bookElements = driver.find_elements(By.CSS_SELECTOR, 'article.product_pod h3 > a')\n",
        "        for element in bookElements:\n",
        "            absoluteUrl = urljoin(driver.current_url, element.get_attribute('href'))\n",
        "            bookUrls.append(absoluteUrl)\n",
        "\n",
        "        try:\n",
        "            nextButton = driver.find_element(By.CSS_SELECTOR, '.next > a')\n",
        "            nextButton.click()\n",
        "            time.sleep(0.5)\n",
        "        except NoSuchElementException:\n",
        "            break\n",
        "\n",
        "    print(f\"{len(bookUrls)} book URLs found.\")\n",
        "    return bookUrls\n",
        "\n",
        "def scrapeBookDetails(driver, bookUrl):\n",
        "    \"\"\"\n",
        "    Phase 2: Visits a book's page and extracts all detailed information.\n",
        "    \"\"\"\n",
        "    driver.get(bookUrl)\n",
        "\n",
        "    ratingMap = {\"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5}\n",
        "\n",
        "    def getTableData(label):\n",
        "        try:\n",
        "            return driver.find_element(By.XPATH, f'//th[text()=\"{label}\"]/following-sibling::td').text\n",
        "        except NoSuchElementException:\n",
        "            return None\n",
        "\n",
        "    name = driver.find_element(By.TAG_NAME, 'h1').text\n",
        "    category = driver.find_element(By.CSS_SELECTOR, '.breadcrumb li:nth-of-type(3) a').text\n",
        "    relativeImageUrl = driver.find_element(By.CSS_SELECTOR, '#product_gallery img').get_attribute('src')\n",
        "    absoluteImageUrl = urljoin(bookUrl, relativeImageUrl)\n",
        "\n",
        "    try:\n",
        "        description = driver.find_element(By.XPATH, '//div[@id=\"product_description\"]/following-sibling::p').text\n",
        "        hasDescription = True\n",
        "    except NoSuchElementException:\n",
        "        description = \"\"\n",
        "        hasDescription = False\n",
        "\n",
        "    ratingText = driver.find_element(By.CSS_SELECTOR, 'p.star-rating').get_attribute('class').split()[-1]\n",
        "    rating = ratingMap.get(ratingText, 0)\n",
        "\n",
        "    upc = getTableData(\"UPC\")\n",
        "    productType = getTableData(\"Product Type\")\n",
        "    priceExclTax = getTableData(\"Price (excl. tax)\")\n",
        "    priceInclTax = getTableData(\"Price (incl. tax)\")\n",
        "    tax = getTableData(\"Tax\")\n",
        "    availability = getTableData(\"Availability\")\n",
        "    numberOfReviews = getTableData(\"Number of reviews\")\n",
        "\n",
        "    return {\n",
        "        'Name': name,\n",
        "        'Category': category,\n",
        "        'UPC': upc,\n",
        "        'Product Type': productType,\n",
        "        'Price (excl. tax)': priceExclTax,\n",
        "        'Price (incl. tax)': priceInclTax,\n",
        "        'Tax': tax,\n",
        "        'Availability': availability,\n",
        "        '# Reviews': numberOfReviews,\n",
        "        'Rating': rating,\n",
        "        'Has Description': hasDescription,\n",
        "        'Image URL': absoluteImageUrl,\n",
        "        'Description': description\n",
        "    }\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Orchestrates the entire scraping process and saves the results.\n",
        "    \"\"\"\n",
        "    browserOptions = ChromeOptions()\n",
        "    browserOptions.add_argument(\"--headless\")\n",
        "    browserOptions.add_argument(\"--no-sandbox\")\n",
        "    browserOptions.add_argument(\"--window-size=1920,1080\")\n",
        "\n",
        "    driver = Chrome(options=browserOptions)\n",
        "\n",
        "    # Phase 1\n",
        "    allUrls = getAllBookUrls(driver, HOMEPAGE)\n",
        "\n",
        "    # Phase 2\n",
        "    print(\"\\nPhase 2: Extracting details for each book...\")\n",
        "    allBookDetails = []\n",
        "    for url in tqdm(allUrls, desc=\"Processing books\"):\n",
        "        details = scrapeBookDetails(driver, url)\n",
        "        allBookDetails.append(details)\n",
        "\n",
        "    driver.quit()\n",
        "\n",
        "    print(\"\\nCreating DataFrame and saving to CSV...\")\n",
        "    df = pd.DataFrame(allBookDetails)\n",
        "    df.to_csv(\"detailed_books.csv\", index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(\"\\nProcess finished. Data saved to 'detailed_books.csv'\")\n",
        "    print(\"First 5 rows of the DataFrame:\")\n",
        "    print(df.head())"
      ],
      "metadata": {
        "id": "XK2myh-7R3Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxMnn8BZS_LB",
        "outputId": "ab136104-dbb8-4856-d973-75516e39fc74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 1: Collecting all book URLs...\n",
            "1000 book URLs found.\n",
            "\n",
            "Phase 2: Extracting details for each book...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing books: 100%|██████████| 1000/1000 [10:34<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating DataFrame and saving to CSV...\n",
            "\n",
            "Process finished. Data saved to 'detailed_books.csv'\n",
            "First 5 rows of the DataFrame:\n",
            "                                    Name            Category  \\\n",
            "0                   A Light in the Attic              Poetry   \n",
            "1                     Tipping the Velvet  Historical Fiction   \n",
            "2                             Soumission             Fiction   \n",
            "3                          Sharp Objects             Mystery   \n",
            "4  Sapiens: A Brief History of Humankind             History   \n",
            "\n",
            "                UPC Product Type Price (excl. tax) Price (incl. tax)    Tax  \\\n",
            "0  a897fe39b1053632        Books            £51.77            £51.77  £0.00   \n",
            "1  90fa61229261140a        Books            £53.74            £53.74  £0.00   \n",
            "2  6957f44c3847a760        Books            £50.10            £50.10  £0.00   \n",
            "3  e00eb4fd7b871a48        Books            £47.82            £47.82  £0.00   \n",
            "4  4165285e1663650f        Books            £54.23            £54.23  £0.00   \n",
            "\n",
            "              Availability # Reviews  Rating  Has Description  \\\n",
            "0  In stock (22 available)         0       3             True   \n",
            "1  In stock (20 available)         0       1             True   \n",
            "2  In stock (20 available)         0       1             True   \n",
            "3  In stock (20 available)         0       4             True   \n",
            "4  In stock (20 available)         0       5             True   \n",
            "\n",
            "                                           Image URL  \\\n",
            "0  https://books.toscrape.com/media/cache/fe/72/f...   \n",
            "1  https://books.toscrape.com/media/cache/08/e9/0...   \n",
            "2  https://books.toscrape.com/media/cache/ee/cf/e...   \n",
            "3  https://books.toscrape.com/media/cache/c0/59/c...   \n",
            "4  https://books.toscrape.com/media/cache/ce/5f/c...   \n",
            "\n",
            "                                         Description  \n",
            "0  It's hard to imagine a world without A Light i...  \n",
            "1  \"Erotic and absorbing...Written with starling ...  \n",
            "2  Dans une France assez proche de la nôtre, un h...  \n",
            "3  WICKED above her hipbone, GIRL across her hear...  \n",
            "4  From a renowned historian comes a groundbreaki...  \n"
          ]
        }
      ]
    }
  ]
}